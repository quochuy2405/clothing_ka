{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import cv2\n",
    "import pprint\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models\n",
    "\n",
    "from data.custom_dataset_data_loader import CustomDatasetDataLoader, sample_data\n",
    "\n",
    "\n",
    "from options_head.base_options import parser\n",
    "from utils.tensorboard_utils import board_add_images\n",
    "from utils.saving_utils import save_checkpoints\n",
    "from utils.saving_utils import load_checkpoint, load_checkpoint_mgpu\n",
    "from utils.distributed import get_world_size, set_seed, synchronize, cleanup\n",
    "\n",
    "from networks import U2NET\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1000\"\n",
    "print('cuda',torch.cuda.is_available())\n",
    "torch.cuda.empty_cache() \n",
    "torch.cuda.set_per_process_memory_fraction(fraction=1.0)\n",
    "\n",
    "print('memory_allocated',torch.cuda.memory_allocated())\n",
    "print('memory_reserved',torch.cuda.memory_reserved())\n",
    "\n",
    "def options_printing_saving(opt):\n",
    "    os.makedirs(opt.logs_dir, exist_ok=True)\n",
    "    os.makedirs(opt.save_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(opt.save_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(opt.save_dir, \"checkpoints\"), exist_ok=True)\n",
    "\n",
    "    # Saving options in yml file\n",
    "    option_dict = vars(opt)\n",
    "    with open(os.path.join(opt.save_dir, \"training_options.yml\"), \"w\") as outfile:\n",
    "        yaml.dump(option_dict, outfile)\n",
    "\n",
    "    for key, value in option_dict.items():\n",
    "        print(key, value)\n",
    "\n",
    "\n",
    "def training_loop(opt):\n",
    "\n",
    "    if opt.distributed:\n",
    "        local_rank = int(os.environ.get(\"LOCAL_RANK\"))\n",
    "        # Unique only on individual node.\n",
    "        device = torch.device(f\"cuda:{local_rank}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        local_rank = 0\n",
    "\n",
    "    u_net = U2NET(in_ch=3, out_ch=4)\n",
    "    if opt.continue_train:\n",
    "        u_net = load_checkpoint(u_net, opt.unet_checkpoint)\n",
    "    u_net = u_net.to(device)\n",
    "    u_net.train()\n",
    "\n",
    "    if local_rank == 0:\n",
    "        with open(os.path.join(opt.save_dir, \"networks.txt\"), \"w\") as outfile:\n",
    "            print(\"<----U-2-Net---->\", file=outfile)\n",
    "            print(u_net, file=outfile)\n",
    "\n",
    "    if opt.distributed:\n",
    "        u_net = nn.parallel.DistributedDataParallel(\n",
    "            u_net,\n",
    "            device_ids=[local_rank],\n",
    "            output_device=local_rank,\n",
    "            broadcast_buffers=False,\n",
    "        )\n",
    "        print(\"Going super fast with DistributedDataParallel\")\n",
    "\n",
    "    # initialize optimizer\n",
    "    optimizer = optim.Adam(\n",
    "        u_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0\n",
    "    )\n",
    "\n",
    "    custom_dataloader = CustomDatasetDataLoader()\n",
    "    custom_dataloader.initialize(opt)\n",
    "    loader = custom_dataloader.get_loader()\n",
    "\n",
    "    if local_rank == 0:\n",
    "        dataset_size = len(custom_dataloader)\n",
    "        print(\"Total number of images avaliable for training: %d\" % dataset_size)\n",
    "        writer = SummaryWriter(opt.logs_dir)\n",
    "        print(\"Entering training loop!\")\n",
    "\n",
    "    # loss function\n",
    "    weights = np.array([1, 1.5, 1.5, 1.5], dtype=np.float32)\n",
    "    weights = torch.from_numpy(weights).to(device)\n",
    "    loss_CE = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "\n",
    "    pbar = range(opt.iter)\n",
    "    get_data = sample_data(loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Main training loop\n",
    "    for itr in pbar:\n",
    "        data_batch = next(get_data)\n",
    "        image, label = data_batch\n",
    "        image = Variable(image.to(device))\n",
    "        label = label.type(torch.long)\n",
    "        label = Variable(label.to(device))\n",
    "\n",
    "        d0, d1, d2, d3, d4, d5, d6 = u_net(image)\n",
    "\n",
    "        loss0 = loss_CE(d0, label)\n",
    "        loss1 = loss_CE(d1, label)\n",
    "        loss2 = loss_CE(d2, label)\n",
    "        loss3 = loss_CE(d3, label)\n",
    "        loss4 = loss_CE(d4, label)\n",
    "        loss5 = loss_CE(d5, label)\n",
    "        loss6 = loss_CE(d6, label)\n",
    "        del d1, d2, d3, d4, d5, d6\n",
    "\n",
    "        total_loss = loss0 * 1.5 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
    "\n",
    "        for param in u_net.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        total_loss.backward()\n",
    "        if opt.clip_grad != 0:\n",
    "            nn.utils.clip_grad_norm_(u_net.parameters(), opt.clip_grad)\n",
    "        optimizer.step()\n",
    "\n",
    "        if local_rank == 0:\n",
    "            # printing and saving work\n",
    "            if itr % opt.print_freq == 0:\n",
    "                pprint.pprint(\n",
    "                    \"[step-{:08d}] [time-{:.3f}] [total_loss-{:.6f}]  [loss0-{:.6f}]\".format(\n",
    "                        itr, time.time() - start_time, total_loss, loss0\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if itr % opt.image_log_freq == 0:\n",
    "                d0 = F.log_softmax(d0, dim=1)\n",
    "                d0 = torch.max(d0, dim=1, keepdim=True)[1]\n",
    "                visuals = [[image, torch.unsqueeze(label, dim=1) * 85, d0 * 85]]\n",
    "                board_add_images(writer, \"grid\", visuals, itr)\n",
    "\n",
    "            writer.add_scalar(\"total_loss\", total_loss, itr)\n",
    "            writer.add_scalar(\"loss0\", loss0, itr)\n",
    "\n",
    "            if itr % opt.save_freq == 0:\n",
    "                save_checkpoints(opt, itr, u_net)\n",
    "\n",
    "    print(\"Training done!\")\n",
    "    if local_rank == 0:\n",
    "        itr += 1\n",
    "        save_checkpoints(opt, itr, u_net)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    opt = parser()\n",
    "\n",
    "    if opt.distributed:\n",
    "        if int(os.environ.get(\"LOCAL_RANK\")) == 0:\n",
    "            options_printing_saving(opt)\n",
    "    else:\n",
    "        options_printing_saving(opt)\n",
    "\n",
    "    try:\n",
    "        if opt.distributed:\n",
    "            print(\"Initialize Process Group...\")\n",
    "            torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "            synchronize()\n",
    "\n",
    "        set_seed(1000)\n",
    "        training_loop(opt)\n",
    "        cleanup(opt.distributed)\n",
    "        print(\"Exiting..............\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        cleanup(opt.distributed)\n",
    "\n",
    "    except Exception:\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        cleanup(opt.distributed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
